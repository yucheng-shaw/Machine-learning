{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Goal\n",
    "\n",
    "The goal of this homework is to do <span style=\"background-color:yellow\"> linear regression </span> on Boston's house prices. After our training, we will have a model that can take in several attributes that may be related to house prices in Boston and give a prediction about the cost of this house.\n",
    "\n",
    "\n",
    "## Input Data Description\n",
    "<ul>\n",
    "The dataset is available in scikit-learn under <span style=\"background-color:yellow\"> sklearn.datasets </span> as load_boston.\n",
    "The data include...\n",
    "<li> total number of 506 cases\n",
    "<li> each case has 13 attributes that is relavent to the house price and\n",
    "<li> 1 target attribute: house price in some unit\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function load_boston at 0x10dee3730>\n",
      "(506, 13)\n",
      "(506,)\n",
      "[24.  21.6 34.7 33.4 36.2]\n",
      "[2.7310e-02 0.0000e+00 7.0700e+00 0.0000e+00 4.6900e-01 6.4210e+00\n",
      " 7.8900e+01 4.9671e+00 2.0000e+00 2.4200e+02 1.7800e+01 3.9690e+02\n",
      " 9.1400e+00]\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset using sklearn.datasets and parse using pandas and numpy\n",
    "\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "#y = np.zeros(506,)\n",
    "#y[0:100] = 1\n",
    "print(load_boston)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(y[0:5])\n",
    "print(X[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "k=np.array([[1,2,3,3], [3,6,7,8]])\n",
    "print(k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 13)\n",
      "(51, 13)\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "#randomly split the data set into train set and test set\n",
    "#test_size: portion of data set being used, random_state: randomizer we use\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(type(y_test[6]))\n",
    "#How do the splitter decide the ratio of data set in train and test set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 455 examples with 13 features\n",
      "Predicting on 51 examples with 13 features\n",
      "\n",
      "The mean_squared_error of prediction is 7.64\n",
      "Run time with all features: 0.26 sec\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "print(\"Training on %i examples with %i features\"%X_train.shape)\n",
    "\n",
    "#Use default parameters and train on full dataset\n",
    "#nthread is relavent to parallel computing and (seed is used to generate the fold randomly for cross validation of \n",
    "#in/ out sample error), n_estimators is the number of boosted trees\n",
    "XGBregressor = xgb.sklearn.XGBRegressor(n_estimators=500, booster='gbtree', max_depth=4, learning_rate=0.01,\\\n",
    "                                        min_child_weight=2)\n",
    "#Train and time regressor\n",
    "start_time = time.time()\n",
    "XGBregressor.fit(X_train, y_train)\n",
    "run_time = time.time() - start_time\n",
    "\n",
    "#Make Predictions\n",
    "print(\"Predicting on %i examples with %i features\\n\"%X_test.shape)\n",
    "y_pred= XGBregressor.predict(X_test)\n",
    "\n",
    "#Print Results\n",
    "#print(\"Model Accuracy with all features: {:.2f}%\".format(100*XGBregressor.score(X_test, y_test)))\n",
    "print(\"The mean_squared_error of prediction is {:.2f}\".format(mean_squared_error(y_test,y_pred)))\n",
    "print(\"Run time with all features: {:.2f} sec\\n\\n\".format(run_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems\n",
    "<ul>\n",
    "<li>After searching through some literatures, I found that the boost mechanism can also be used for linear regression via changing classifiers to linear functions. The XGBoost webpage also have descriptions about setting the learner to be linear HOWEVER it says that in this case, there will be no 'feature importances' which make sense. \n",
    "(cf.  https://xgboost.readthedocs.io/en/latest/python/python_api.html  property feature_importances_) \n",
    "<li>However, I still find some other boosting package such as sklearn ensemble that can compute feature importances for linear regression model which I find strange. \n",
    "(c.f. https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py )\n",
    "<li>Next question now: how is there still <span style=\"background-color:yellow\"> feature_ importances </span> instead of <span style=\"background-color:yellow\"> coef_ attribute </span> in sklearn linear regression model? \n",
    "<li>I see... It's a problem of API of XGBoost. In 'XGBClassifier' one can only train logistic regression, while for 'XGBRegressor', one can do linear regression with gradient boost.\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAREAAAEWCAYAAABBkaM2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYknEGBMUSyLGmKBYEjHGBMWSiDEmKP8fkA+zy6+7fYAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113be3c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "fig=plt.figure()\n",
    "xgb.plot_importance(XGBregressor, ax=plt.gca())\n",
    "fig.subplots_adjust(left=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelectFromModel select important features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                       colsample_bylevel=1, colsample_bynode=1,\n",
       "                                       colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                                       importance_type='gain',\n",
       "                                       interaction_constraints=None,\n",
       "                                       learning_rate=0.01, max_delta_step=0,\n",
       "                                       max_depth=4, min_child_weight=2,\n",
       "                                       missing=nan, monotone_constraints=None,\n",
       "                                       n_estimators=500, n_jobs=0,\n",
       "                                       num_parallel_tree=1,\n",
       "                                       objective='reg:squarederror',\n",
       "                                       random_state=0, reg_alpha=0,\n",
       "                                       reg_lambda=1, scale_pos_weight=1,\n",
       "                                       subsample=1, tree_method=None,\n",
       "                                       validate_parameters=False,\n",
       "                                       verbosity=None),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=0.01)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pruning features in model with SelectFromModel\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "sfm = SelectFromModel(XGBregressor, threshold=0.01)\n",
    "\n",
    "#train\n",
    "sfm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features after pruning:  10\n",
      "Predicting on 51 examples with 10 features\n",
      "\n",
      "The mean_squared_error of prediction is 7.42\n",
      "Run time with all features: 0.24 sec\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_features = sfm.transform(X_train).shape[1]\n",
    "\n",
    "#prune training data\n",
    "print('number of features after pruning: ', n_features)\n",
    "pruned_X_train = sfm.transform(X_train)\n",
    "\n",
    "#Train and time regressor with data after pruning the features\n",
    "start_time = time.time()\n",
    "XGBregressor.fit(pruned_X_train, y_train)\n",
    "run_time = time.time() - start_time\n",
    "\n",
    "#prune testing data\n",
    "pruned_X_test = sfm.transform(X_test)\n",
    "\n",
    "#Make Predictions\n",
    "print(\"Predicting on %i examples with %i features\\n\"%pruned_X_test.shape)\n",
    "y_pred= XGBregressor.predict(pruned_X_test)\n",
    "\n",
    "#Print Results\n",
    "#print(\"Model Accuracy with all features: {:.2f}%\".format(100*XGBregressor.score(X_test, y_test)))\n",
    "print(\"The mean_squared_error of prediction is {:.2f}\".format(mean_squared_error(y_test,y_pred)))\n",
    "print(\"Run time with all features: {:.2f} sec\\n\\n\".format(run_time))\n",
    "\n",
    "#Print Results\n",
    "#print(\"The mean_squared_error of prediction is {:.2f}\".format(mean_squared_error(y_test,y_pred)))\n",
    "#print(\"Run time with all features: {:.2f} sec\\n\\n\".format(run_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "The error after pruning the training features has slightly decrease, which is desired. //ignore the following //I think this may due to there exists better choice of hyperparameter for this particular set of features. To deal with this problem and decrease the error, we can use GridSearchCV to do the hyperparameter tuning. But, GridSearchCV seems to do hyperparameter testing with 'model' itself , which is irrelavent to the 'input data'. Or, the optimization actually start at .fit()? if so, then the grid search has take the training data into account. and the error should drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:    2.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#Create values to search over\n",
    "cv_params = {'max_depth': [2,3,4], 'min_child_weight': [3,4,5], 'learning_rate':[0.18,0.2,0.22]}\n",
    "ind_params = {'n_estimators': 100, 'seed':1, 'colsample_bytree': 1}\n",
    "#**ind_params\n",
    "opt_XGBregressor = GridSearchCV(xgb.XGBRegressor(), \n",
    "                             cv_params, \n",
    "                             scoring = 'neg_mean_squared_error', cv = 5, n_jobs = -1, verbose=3)\n",
    "\n",
    "#opt_XGBregressor.get_params()\n",
    "opt_XGBregressor.fit(pruned_X_train, y_train)\n",
    "#sorted(opt_XGBregressor.cv_results_.keys())\n",
    "\n",
    "#get the best params\n",
    "print(opt_XGBregressor.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean_squared_error of prediction is 7.68\n"
     ]
    }
   ],
   "source": [
    "y_pred= opt_XGBregressor.predict(pruned_X_test)\n",
    "\n",
    "#Print Results\n",
    "print(\"The mean_squared_error of prediction is {:.2f}\".format(mean_squared_error(y_test,y_pred)))\n",
    "#print(\"Run time with all features: {:.2f} sec\\n\\n\".format(run_time))\n",
    "#8.07(un-pruned)-> 8.26(pruned)->8.26(take out ind_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "1. The error after pruning (13 features-->5 features): 7.64-->7.42 decreased \n",
    "2. The error after GridSearchCV(with pruned features): 7.64-->7.68 increased. \n",
    "\n",
    "Given the abouve facts, it is only possible to explain that the methond of \"optimized by cross-validated\" is not good enough compared to the hyperparameters found by this reference. https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py And is certainly not simply training with {given hyperparameters, all training data} and compare the error. I look up for explanation of cross validation in this reference. https://medium.com/@chih.sheng.huang821/交叉驗證-cross-validation-cv-3b2c714b18db"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
